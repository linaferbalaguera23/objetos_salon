# objetos_salon
## Proyecto colaborativo: Reconocimiento de objetos con TensorFlow

* Este repositorio forma parte del m√≥dulo de **Redes Convolucionales** 2025-3
* En el curso **BigData**
* Impartido por Gerardo Mu√±oz

---

## Objetivo
Construir, entrenar y evaluar un modelo de visi√≥n que identifique objetos del entorno grabados por los estudiantes, utilizando redes convolucionales, autoencoders y clasificadores.

---

## Objetos a detectar
Cada estudiante grabar√° un video corto (1 a 3 segundos) de los siguientes objetos del sal√≥n:

- üß∞ teclado  
- üñ±Ô∏è mouse  
- üíª pantalla  
- üñ•Ô∏è cpu  
- ü™ë silla  
- üß´ masa

>  Todos los videos deben tomarse en el entorno del aula o laboratorio para mantener consistencia visual.

---

## üìÅ Estructura del repositorio

```
data/
‚îú‚îÄüìÅ raw/ # Videos originales
‚îÇ ‚îú‚îÄ‚îÄ 20202020202_teclado.mp4
‚îÇ ‚îú‚îÄ‚îÄ 20202020202_mouse.mp4
‚îÇ ‚îî‚îÄ‚îÄ ...
‚îú‚îÄüìÅ processed/ # Frames extra√≠dos por clase
‚îÇ ‚îú‚îÄüìÅ teclado/
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ 20202020202_0001.jpg
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ 20202020202_0002.jpg
‚îÇ ‚îú‚îÄüìÅ mouse/
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ 20202020202_0001.jpg
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ 20202020202_0002.jpg
‚îÇ ‚îî‚îÄ‚îÄ ...
notebooks/
‚îú‚îÄ‚îÄ 20202020202.ipynb # Experimentos y entrenamiento por estudiante
‚îú‚îÄ‚îÄ 20202020202.ipynb
‚îî‚îÄ‚îÄ ...
models/
‚îú‚îÄ‚îÄ 20202020202_autoencoder.h5 # Pesos entrenados del autoencoder
‚îú‚îÄ‚îÄ 20202020202_classifier.h5 # Pesos del clasificador
‚îî‚îÄ‚îÄ ...
```

>  Los nombres de archivos siguen el formato:
> - Videos: `"{codigo}_{objeto}.mp4"`
> - Frames: `"{objeto}/{codigo}_{indice}.jpg"`
> - Notebooks: `"{codigo}.ipynb"`
> - Pesos: `"{codigo}_autoencoder.h5"` o `"{codigo}_classifier.h5"`

---

## C√≥mo contribuir

1. **Haz un fork** de este repositorio.  
2. **Agrega tu video** en `data/raw/` con el nombre `"{codigo}_{objeto}.mp4"`.  
3. **Extrae los frames** y col√≥calos en `data/processed/{objeto}/{codigo}_{indice}.jpg`.  
4. **Crea tu notebook** en `notebooks/{codigo}.ipynb` con tus experimentos.  
5. Si entrenas modelos, guarda los pesos en `models/` con el formato indicado.  
6. **Actualiza este README** agregando tu nombre y el objeto que grabaste.  
7. **Haz un Pull Request** al repositorio principal de la organizaci√≥n.

---

## Requisitos b√°sicos

* Extraer frames (1 cada 10‚Äì15 cuadros).
* Entrenar un autoencoder con las im√°genes de todos los objetos.
* Usar el encoder para extraer features de cada imagen.
* Entrenar un clasificador (CNN) para predecir el tipo de objeto.
* Evaluar el modelo con los videos de otros compa√±eros.

---

## Resultados esperados
* Representaciones latentes del autoencoder (espacio comprimido de im√°genes).
* Clasificaci√≥n de objetos del entorno.
* Comparaci√≥n de rendimiento entre distintos entornos o c√°maras.

---

## Participantes
| C√≥digo | Nombre | Objeto | Video |
|-|-|-|-|
|20202020202 | Nombre | teclado | data/raw/20202020202_teclado.mp4 |
|20202020202 | Nombre | teclado | data/raw/20202020202_mouse.mp4 |

(Agrega tu fila al contribuir)

---


## Licencia
Este proyecto se distribuye bajo la licencia MIT.
Puedes reutilizar y modificar el contenido con fines educativos y de investigaci√≥n.

---


## Cr√©ditos
Desarrollado por los estudiantes del curso con el apoyo del equipo docente.
Proyecto inspirado en la idea de crear datasets colaborativos reales para aplicar redes convolucionales en entornos cotidianos.
